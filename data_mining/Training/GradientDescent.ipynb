{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2bb67f",
   "metadata": {},
   "source": [
    "# **Descenso de gradiente**\n",
    "\n",
    "El Descenso de Gradiente es un algoritmo de optimización muy genérico. La idea general es ajustar los parámetros de forma iterativa para minimizar una función de costo. \n",
    "\n",
    "Supón que estás perdido en las montañas; solo puedes sentir la inclinación del suelo bajo tus pies. Una buena estrategia para llegar al fondo del valle rápidamente es ir cuesta abajo en la dirección de la pendiente más pronunciada. Esto es exactamente lo que hace el Descenso de Gradiente: mide el gradiente local de la función de error con respecto al vector de parámetros $\\theta$, y avanza en la dirección del gradiente descendente. \n",
    "\n",
    "Concretamente, comienzas llenando $\\theta$ con valores aleatorios, y luego lo mejoras gradualmente, dando un pequeño paso a la vez (*learning rate*), intentando en cada paso disminuir la función de costo (por ejemplo, el MSE), hasta que el algoritmo converge en un mínimo.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"img/gradientDescent01.png\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Un parámetro importante en el Descenso de Gradiente es el tamaño de los pasos, determinado por el hiperparámetro llamado tasa de aprendizaje (learning rate). Si la tasa de aprendizaje es demasiado pequeña, el algoritmo tendrá que pasar por muchas iteraciones para converger, pero si la tasa de aprendizaje es demasiado alta, podrías saltar de un lado a otro del valle y terminar en el lado opuesto, posiblemente incluso más arriba de donde estabas antes\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; align-items: center; gap: 40px;\">\n",
    "  <img src=\"img/gradientDescent02.png\" alt=\"Izquierda\" width=\"400\">\n",
    "  <img src=\"img/gradientDescent03.png\" alt=\"Derecha\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "No todas las funciones de costo son parabolas. Puede haber agujeros, crestas, mesetas y todo tipo de terrenos irregulares, lo que hace que la convergencia al mínimo sea muy difícil. En la Figura muestra los dos desafíos principales del Descenso de Gradiente: si la inicialización aleatoria comienza el algoritmo a la izquierda, entonces convergerá a un mínimo local, que no es tan bueno como el mínimo global. Si comienza a la derecha, entonces tardará mucho tiempo en atravesar la meseta, y si te detienes demasiado pronto, nunca alcanzarás el mínimo global.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"img/gradientDescent04.png\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Afortunadamente, la función de costo MSE para un modelo de Regresión Lineal resulta ser una función parabola (convexa), esto implica que no hay mínimos locales, solo un mínimo global.\n",
    "\n",
    "---\n",
    "\n",
    "- Cuando utilices el Descenso de Gradiente, debes asegurarte de que todas las características tengan una escala similar (por ejemplo, usando la clase `StandardScaler` de **Scikit-Learn**); de lo contrario, el algoritmo tardará mucho más tiempo en converger.\n",
    "\n",
    "    ```python\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "Para implementar el Descenso de Gradiente, necesitas calcular el gradiente de la función de costo con respecto a cada parámetro del modelo $\\theta_j$. La siguiente ecuacion calcula la derivada parcial de la función de costo con respecto al parámetro $\\theta_j$, denotada como $\\frac{\\partial}{\\partial \\theta_j} MSE(\\theta)$.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta_j} \\text{MSE}(\\theta) =\n",
    "\\frac{2}{m} \\sum_{i=1}^{m} \n",
    "\\left( \\theta^T x^{(i)} - y^{(i)} \\right) x_j^{(i)}\n",
    "$$\n",
    "\n",
    "En lugar de calcular estas derivadas parciales individualmente, puedes calcularlas todas de una sola vez. El vector gradiente, denotado como $\\nabla_\\theta MSE(\\theta)$, contiene todas las derivadas parciales de la función de costo (una para cada parámetro del modelo).\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} \\text{MSE}(\\theta) =\n",
    "\\begin{pmatrix}\n",
    "\\frac{\\partial}{\\partial \\theta_0} \\text{MSE}(\\theta) \\\\\n",
    "\\frac{\\partial}{\\partial \\theta_1} \\text{MSE}(\\theta) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial}{\\partial \\theta_n} \\text{MSE}(\\theta)\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\frac{2}{m} \\mathbf{X}^T (\\mathbf{X}\\theta - \\mathbf{y})\n",
    "$$\n",
    "\n",
    "Una vez que tienes el vector gradiente, que apunta hacia arriba, simplemente ve en la dirección opuesta para ir hacia abajo. Esto significa restar $\\nabla_\\theta MSE(\\theta)$ de $\\theta$. Aquí es donde entra en juego la tasa de aprendizaje $\\eta$ (eta): multiplica el vector gradiente por $\\eta$ para determinar el tamaño del paso cuesta abajo. La ecuacion de paso del algoritmo descendente de gradiente es:\n",
    "\n",
    "$$\n",
    "\\theta^{(\\text{paso siguiente})} = \\theta - \\eta \\nabla_\\theta MSE(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f6cf6",
   "metadata": {},
   "source": [
    "### Implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd785c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_bias(X):\n",
    "    \"\"\"Devuelve una nueva matriz con una columna de 1s al principio (X_0=1).\"\"\"\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    return X_b\n",
    "\n",
    "def gradientDescent(lr,n_epochs,X, y):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    theta = np.random.randn(n,1)\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        gradients = 2/m * X.T @ (X @ theta - y)\n",
    "        theta -= lr * gradients\n",
    "\n",
    "    return theta\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c892f3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros aprendidos (θ):\n",
      "[[3.92874385]\n",
      " [2.96360959]\n",
      " [2.00046389]\n",
      " [0.99695659]]\n"
     ]
    }
   ],
   "source": [
    "m = 100         # Cantidad de datos\n",
    "n = 3           # Features\n",
    "\n",
    "X = 2 * np.random.randn(m, n)\n",
    "X_b = add_bias(X)\n",
    "\n",
    "true_theta = np.array([[4], [3], [2], [1]]) \n",
    "\n",
    "y = X_b @ true_theta + np.random.rand(m, 1)\n",
    "\n",
    "theta = gradientDescent(0.1,10,X_b,y)\n",
    "\n",
    "print(\"Parámetros aprendidos (θ):\")\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a387c",
   "metadata": {},
   "source": [
    "\n",
    "## Normalizacion\n",
    "\n",
    "Para acelerar la convergencia del algoritmo, las características se deben normalizar de modo que $\\bar{X_j}=0$ y $\\sigma(X_j)=1$, es decir, que los valores de cada variable $X_j$ pasen a tener media 0 y desviación 1. Para ello, se aplica la siguiente expresión.\n",
    "\n",
    "$$\n",
    "x_j^{(i)} = \\frac{x_j^{(i)}-\\bar{X_j}}{\\sigma(X_j)}\n",
    "$$\n",
    "\n",
    "El algoritmo de la gradiente descendiente devuelve los coeficientes $\\alpha$ que minimizan el coste para las variables normalizadas. Por tanto, hay transformarlos para su aplicación sobre las variables en los rangos originales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fede1b3",
   "metadata": {},
   "source": [
    "# Descenso de gradiente estocástico (SGD)\n",
    "\n",
    "El principal problema del Descenso de Gradiente por Lotes es el hecho de que utiliza todo el conjunto de entrenamiento para calcular los gradientes en cada paso, lo que lo hace muy lento cuando el conjunto de entrenamiento es grande. En el extremo opuesto, el Descenso de Gradiente Estocástico simplemente elige una instancia aleatoria del conjunto de entrenamiento en cada paso y calcula los gradientes basándose únicamente en esa única instancia.\n",
    "\n",
    "Funcionamiento:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"img/SGD01.png\" width=\"600\">\n",
    "</p>\n",
    "\n",
    "- En el descenso de gradientes tradicional, los gradientes se calculan en función de todo el conjunto de datos, lo que puede resultar computacionalmente costoso para conjuntos de datos grandes.\n",
    "- En el descenso de gradiente estocástico, el gradiente se calcula para cada ejemplo de entrenamiento (o un pequeño subconjunto de ejemplos de entrenamiento) en lugar de para todo el conjunto de datos.\n",
    "\n",
    "La regla de actualización del descenso del gradiente estocástico es:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} \\text{MSE}(\\theta)_{(i)} = 2 x_i^{T}\n",
    "\\left( x_i \\theta - y_{i} \\right)\n",
    "$$\n",
    "\n",
    "La diferencia clave con el descenso de gradiente tradicional radica en que, en SGD, las actualizaciones de parámetros se basan en un único punto de datos, no en todo el conjunto de datos. La selección aleatoria de puntos de datos introduce estocasticidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f205261",
   "metadata": {},
   "source": [
    "### Implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c936bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochasticGradientDescent(lr0,lr1,n_epochs,X, y):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    theta = np.random.randn(n,1)\n",
    "\n",
    "    def learning_schedule(t):\n",
    "        return lr0 / (t + lr1)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(m):\n",
    "            random_index = np.random.randint(m)\n",
    "            xi = X_b[random_index:random_index+1]\n",
    "            yi = y[random_index:random_index+1]\n",
    "            gradients = 2 * xi.T @ (xi @ theta - yi)\n",
    "            eta = learning_schedule(epoch * m + i)\n",
    "            theta = theta - eta * gradients\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f59a9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros aprendidos (θ):\n",
      "[[4.42724463]\n",
      " [3.01872965]\n",
      " [1.99368464]\n",
      " [1.02676199]]\n"
     ]
    }
   ],
   "source": [
    "m = 100         # Cantidad de datos\n",
    "n = 3           # Features\n",
    "\n",
    "X = 2 * np.random.randn(m, n)\n",
    "X_b = add_bias(X)\n",
    "\n",
    "true_theta = np.array([[4], [3], [2], [1]]) \n",
    "\n",
    "y = X_b @ true_theta + np.random.rand(m, 1)\n",
    "\n",
    "theta = stochasticGradientDescent(5,50,10,X_b,y)\n",
    "\n",
    "print(\"Parámetros aprendidos (θ):\")\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8cdba",
   "metadata": {},
   "source": [
    "### Implementacion con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb47be6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercepto (bias): [3.45517509]\n",
      "Coeficientes (θ): [3.0345116  1.86385113 1.32201842]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "m = 100         # Cantidad de datos\n",
    "n = 3           # Features\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = 2 * np.random.rand(m, n)\n",
    "y = 4 + 3*X[:,0] + 2*X[:,1] + X[:,2] + np.random.randn(m)\n",
    "\n",
    "# Escalamos los datos (SGD lo necesita)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Creamos el modelo\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\n",
    "\n",
    "# Entrenamos\n",
    "sgd_reg.fit(X, y)\n",
    "\n",
    "print(\"Intercepto (bias):\", sgd_reg.intercept_)\n",
    "print(\"Coeficientes (θ):\", sgd_reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2732a1c4",
   "metadata": {},
   "source": [
    "# Mini-batch Gradient Descent\n",
    "\n",
    "El Mini-batch GD calcula los gradientes en pequeños conjuntos aleatorios de instancias llamados mini-lotes. El progreso del algoritmo en el espacio de parámetros es menos errático que con el SGD, especialmente con mini-lotes relativamente grandes. Como resultado, el Mini-batch GD terminará caminando un poco más cerca del mínimo que el SGD. Pero, por otro lado, puede ser más difícil para este escapar de los mínimos locales.\n",
    "\n",
    "Para un mini batch de tamaño b:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} \\text{MSE}(\\theta) =\n",
    "\\begin{pmatrix}\n",
    "\\frac{\\partial}{\\partial \\theta_0} \\text{MSE}(\\theta) \\\\\n",
    "\\frac{\\partial}{\\partial \\theta_1} \\text{MSE}(\\theta) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial}{\\partial \\theta_b} \\text{MSE}(\\theta)\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\frac{2}{b} \\mathbf{X}^T_B (\\mathbf{X}_B\\theta - \\mathbf{y}_B)\n",
    "$$\n",
    "\n",
    "y la actualizacion es:\n",
    "\n",
    "$$\n",
    "\\theta^{(\\text{paso siguiente})} = \\theta - \\eta \\nabla_\\theta MSE(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af79e6",
   "metadata": {},
   "source": [
    "### Implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db05d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miniBatchGradientDescent(lr,n_epochs,batch_size,X, y):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    theta = np.random.randn(n,1)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "        X_b_shuffled = X_b[shuffled_indices]\n",
    "        y_shuffled = y[shuffled_indices]\n",
    "        for i in range(m):\n",
    "            X_batch = X_b_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "            gradients = 2/batch_size * X_batch.T @ (X_batch @ theta - y_batch)\n",
    "            theta = theta - lr * gradients\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75ac012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros aprendidos (θ):\n",
      "[[4.61781576]\n",
      " [2.90903395]\n",
      " [2.09292983]\n",
      " [1.05783127]]\n"
     ]
    }
   ],
   "source": [
    "m = 100         # Cantidad de datos\n",
    "n = 3           # Features\n",
    "\n",
    "X = 2 * np.random.randn(m, n)\n",
    "X_b = add_bias(X)\n",
    "\n",
    "true_theta = np.array([[4], [3], [2], [1]]) \n",
    "\n",
    "y = X_b @ true_theta + np.random.rand(m, 1)\n",
    "\n",
    "theta = miniBatchGradientDescent(0.1,20,10,X_b,y)\n",
    "\n",
    "print(\"Parámetros aprendidos (θ):\")\n",
    "print(theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
